<!DOCTYPE html> 
<html lang="en" dir="ltr">
    <head>
        <script type="module" src="Javascript/NewNavTest.js" async></script>
        <link rel="stylesheet" href="CSS/newNavigation.css">
        <link href="https://fonts.googleapis.com/css?family=Lemon:400,700" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css?family=Lemonada:400,700" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700" rel="stylesheet">
        <meta charset="UTF-8">
        <meta name = "description" content = "A theory blog post discussing information geographies">
        <meta name = "keywords" content = "blog, posts, OC, POV, theory">
        <link rel="shortcut icon" href="Images/Logo.png" type="image/x-icon">
        <title> Starburst Blogs/Theory </title>
    </head>

    <body>
        <nav class="navbar">
            <a href="#" class="toggle-button">
            <span class="bar"></span>
			<span class="bar"></span>
			<span class="bar"></span>
            </a>
            
            <div class="navbar-links">
                <ul>
                <li><button id="go-back">Back</button></li>
				<li><a href="index.html">Home</a></li>
				<li><a href="theoryBlogHP.html">Theory Blogs</a></li>
				<li><a href="characterBlogHP.html">Character Blogs</a></li>
				<li><a href="designHP.html">Design</a></li>
				<li><a href="about.html">About</a></li>
				<li><button id="go-forward">Forward</button></li>
                </ul>
            </div>
        </nav>

        <header>
            <div class="blog-title">
                <h1 style = "text-align: center; border: 4px solid #851E52;"><b><u>Starburst Blogs</u></b></h1>
            </div>
        </header>

        <section>
            <div class="page-title">
                <h2 style="text-align: center;"><u><b>Theory Blog</b></u></h2>
            </div>
        </section>

        <section class="blog">
            <div class="post-title">
                <h3 style="text-align: center;"><u>Racial Prejudices in Facial Recognition</u></h2>
            </div>

            <div class="blog-post" style="max-width: 700px;">
                <time datetime="2020-06-23">23 June 2020</time>
                <p> “Algorithms often carry all the biases and failures of human employees, but with even less 
                    judgement”, this is what Sen. Ron Wyden (D-Ore.) said in an article in the Washington Post 
                    about a study that was released confirming the racial biases that many facial recognition 
                    systems have. It is no secret that many people of the BIPOC communities have been falsely 
                    identified. This is not something that is surprising or shocking when one takes into account 
                    the Eurocentric concept of what is considered to be ‘normal’ or ‘acceptable’. In a different 
                    article written by Peter Yeung, the director of the Ada Lovelace Institute, Carly Kind, says 
                    that “most training datasets only use photos of celebrities because they’re easier to find. 
                    But these aren’t representative of the world.”</p> 
                <p>Biases will exist in anything made by a human because they impart their thoughts and beliefs, 
                    in some small way, onto what they’ve created. Software and systems are not different and in 
                    the case of identification, it is problematic to not have datasets that are representative of 
                    all people. This especially holds true for countries like the United States or even South Africa, 
                    where there is such diversity in the kinds of people who live there. </p>
                <p>Having facial recognition systems that cannot properly identify people based on age or ethnic and 
                    racial identities is a problem especially when it is what is used by law enforcement to find and 
                    identify suspects. Inaccurate identification could lead to the worst possible outcomes and it 
                    also then ensures that the people actually responsible for a crime will not be apprehended. In 
                    the article by the Washington Post, it states that members of the American Congress voiced their 
                    anger over the lack of regulation and the potential for facial recognition systems to be used as a 
                    tool for discrimination and abuse (Harwell, 2019). </p>
                <p>Creating something that is completely free from bias is nearly impossible, it is possible to reduce 
                    it significantly from where it currently is. One of the biggest issues is that the teams who create 
                    these systems, or those who responsible for their creation are not diverse enough and there is a lack 
                    of representation of BIPOC communities and women and that the datasets that are used are not nearly 
                    representative of the global population. In the article written by Peter Yeung, they state that MIT 
                    researches indicated that the imagery datasets used to develop these facial recognition technologies 
                    and systems were 77% male and 83% white (Yeung, 2020). However, while this is one of the issues, it 
                    is not the root of the bias and that is something a lot more difficult to pin point </p>
                <p>References</p>
                <p> Harwell, D., 2019. Federal Study Confirms Racial Bias Of Many Facial-Recognition Systems, Casts Doubt On Their Expanding Use. [online] The Washington Post. Available at: <https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/> [Accessed 23 June 2020].</p>
                <p> Biometrics ethics: why facial recognition still has racial bias (2020). Available at: https://www.raconteur.net/technology/biometrics-ethics-bias (Accessed: 23 June 2020).</p>

            </div>
        </section>

    </body>

</html>

